{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: Aliah Gie F. Zabala\n",
    "\n",
    "Student ID: 113065424\n",
    "\n",
    "GitHub ID: 182365283\n",
    "\n",
    "Kaggle name: Aliah Gie Zabala\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "![pic0.png](img\\pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home exercises** in the [DM2024-Lab2-master Repo](https://github.com/didiersalazar/DM2024-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework) regarding Emotion Recognition on Twitter by this link: https://www.kaggle.com/competitions/dm-2024-isa-5810-lab-2-homework. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)**. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developing the model for the competition (You can use code and comment on it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 26th, 11:59 pm, Tuesday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Read JSON file\n",
    "df = pd.read_json('tweets_DM.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_df = pd.json_normalize(df['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet.hashtags</th>\n",
       "      <th>tweet.tweet_id</th>\n",
       "      <th>tweet.text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>0x316b80</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x24faed</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          tweet.hashtags tweet.tweet_id  \\\n",
       "0                             [Snapchat]       0x376b20   \n",
       "1          [freepress, TrumpLegacy, CNN]       0x2d5350   \n",
       "2                           [bibleverse]       0x28b412   \n",
       "3                                     []       0x1cd5b0   \n",
       "4                                     []       0x2de201   \n",
       "...                                  ...            ...   \n",
       "1867530  [mixedfeeling, butimTHATperson]       0x316b80   \n",
       "1867531                               []       0x29d0cb   \n",
       "1867532                               []       0x2a6a4f   \n",
       "1867533                               []       0x24faed   \n",
       "1867534                    [Sundayvibes]       0x34be8c   \n",
       "\n",
       "                                                tweet.text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_df # Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all columns from original df except '_source'\n",
    "final_df = source_df.copy()\n",
    "\n",
    "# Concatenate the DataFrames horizontally\n",
    "final_df.rename(columns={'tweet.tweet_id': 'tweet_id', 'tweet.hashtags':'hashtags', 'tweet.text':'text'}, inplace=True)\n",
    "\n",
    "final_df= final_df[['tweet_id', 'hashtags', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>0x316b80</td>\n",
       "      <td>[mixedfeeling, butimTHATperson]</td>\n",
       "      <td>When you buy the last 2 tickets remaining for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>0x29d0cb</td>\n",
       "      <td>[]</td>\n",
       "      <td>I swear all this hard work gone pay off one da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>0x2a6a4f</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Parcel2Go no card left when I wasn't in so I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>0x24faed</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ah, corporate life, where you can date &lt;LH&gt; us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>0x34be8c</td>\n",
       "      <td>[Sundayvibes]</td>\n",
       "      <td>Blessed to be living #Sundayvibes &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id                         hashtags  \\\n",
       "0        0x376b20                       [Snapchat]   \n",
       "1        0x2d5350    [freepress, TrumpLegacy, CNN]   \n",
       "2        0x28b412                     [bibleverse]   \n",
       "3        0x1cd5b0                               []   \n",
       "4        0x2de201                               []   \n",
       "...           ...                              ...   \n",
       "1867530  0x316b80  [mixedfeeling, butimTHATperson]   \n",
       "1867531  0x29d0cb                               []   \n",
       "1867532  0x2a6a4f                               []   \n",
       "1867533  0x24faed                               []   \n",
       "1867534  0x34be8c                    [Sundayvibes]   \n",
       "\n",
       "                                                      text  \n",
       "0        People who post \"add me on #Snapchat\" must be ...  \n",
       "1        @brianklaas As we see, Trump is dangerous to #...  \n",
       "2        Confident of your obedience, I write to you, k...  \n",
       "3                      Now ISSA is stalking Tasha 😂😂😂 <LH>  \n",
       "4        \"Trust is not the same as faith. A friend is s...  \n",
       "...                                                    ...  \n",
       "1867530  When you buy the last 2 tickets remaining for ...  \n",
       "1867531  I swear all this hard work gone pay off one da...  \n",
       "1867532  @Parcel2Go no card left when I wasn't in so I ...  \n",
       "1867533  Ah, corporate life, where you can date <LH> us...  \n",
       "1867534             Blessed to be living #Sundayvibes <LH>  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emotion labels\n",
    "emotion_df = pd.read_csv('emotion.csv')\n",
    "\n",
    "# Load train/test identification\n",
    "identification_df = pd.read_csv('data_identification.csv')\n",
    "    \n",
    "# Merge datasets\n",
    "\n",
    "# First, merge tweets with identification\n",
    "merged_df = final_df.merge(identification_df, on='tweet_id', how='inner')\n",
    "    \n",
    "# Then, merge with emotion labels\n",
    "merged_df = merged_df.merge(emotion_df, on='tweet_id', how='left')\n",
    "    \n",
    "# Split into train and test based on 'identification' column\n",
    "train_df = merged_df[merged_df['identification'] == 'train']\n",
    "test_df = merged_df[merged_df['identification'] == 'test']\n",
    "\n",
    "# Drop the identification column in both training and test sets\n",
    "train_df = train_df.drop('identification', axis=1)\n",
    "test_df = test_df.drop('identification', axis=1)\n",
    "\n",
    "# Drop the emotion column in test set \n",
    "test_df = test_df.drop('emotion', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>[]</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                       hashtags  \\\n",
       "0  0x376b20                     [Snapchat]   \n",
       "1  0x2d5350  [freepress, TrumpLegacy, CNN]   \n",
       "3  0x1cd5b0                             []   \n",
       "5  0x1d755c      [authentic, LaughOutLoud]   \n",
       "6  0x2c91a8                             []   \n",
       "\n",
       "                                                text       emotion  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  anticipation  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...       sadness  \n",
       "3                Now ISSA is stalking Tasha 😂😂😂 <LH>          fear  \n",
       "5  @RISKshow @TheKevinAllison Thx for the BEST TI...           joy  \n",
       "6       Still waiting on those supplies Liscus. <LH>  anticipation  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>[]</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id                           hashtags  \\\n",
       "2   0x28b412                       [bibleverse]   \n",
       "4   0x2de201                                 []   \n",
       "9   0x218443  [materialism, money, possessions]   \n",
       "30  0x2939d5               [GodsPlan, GodsWork]   \n",
       "33  0x26289a                                 []   \n",
       "\n",
       "                                                 text  \n",
       "2   Confident of your obedience, I write to you, k...  \n",
       "4   \"Trust is not the same as faith. A friend is s...  \n",
       "9   When do you have enough ? When are you satisfi...  \n",
       "30  God woke you up, now chase the day #GodsPlan #...  \n",
       "33  In these tough times, who do YOU turn to as yo...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger            39867\n",
       "anticipation    248935\n",
       "disgust         139101\n",
       "fear             63999\n",
       "joy             516017\n",
       "sadness         193437\n",
       "surprise         48729\n",
       "trust           205478\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group to find distribution\n",
    "train_df.groupby(['emotion']).count()['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "labels = train_df['emotion'].unique()\n",
    "post_total = len(train_df)\n",
    "df1 = train_df.groupby(['emotion']).count()['text']\n",
    "df1 = df1.apply(lambda x: round(x*100/post_total,3))\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "plt.bar(df1.index,df1.values)\n",
    "\n",
    "#arrange\n",
    "plt.ylabel('% of instances')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title('Emotion distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Emoji Processing\n",
    "\n",
    "    * Extracts and counts emoji occurrences in text\n",
    "    * Converts emojis to readable text format (e.g., \"😊\" to \"emoji_smilingface\")\n",
    "    * Include emoji frequency information (e.g., \"emoji_smilingface_3x\" for repeated emojis)\n",
    "\n",
    "2. Text Cleaning\n",
    "\n",
    "    * Converts text to lowercase while preserving significant uppercase patterns\n",
    "    * Conversion happens after uppercase word detection to preserve the uppercase patterns\n",
    "\n",
    "3. Special Character Handling:\n",
    "\n",
    "    * Removes URLs, mentions (@user), and hashtags (#topic)\n",
    "        - Hashtags will be concatenated later.\n",
    "    * Standardizes multiple punctuation marks (e.g., \"...\" → \"....\")\n",
    "    * Preserves punctuation patterns (\"!!\", \"??\")\n",
    "    * Identifies and marks words in all caps (excluding \"LH\")\n",
    "        - Example: \"HAPPY\" to \"uppercase_happy\"\n",
    "    * Removes other non-word characters\n",
    "    * Standardizes various forms of \"LH\" (\"LH\", \"<LH>\", \"lh\") to consistent format\n",
    "    * Skips very short words (<= 2 characters) and standalone periods\n",
    "\n",
    "4. More Text Processing\n",
    "\n",
    "    * Stopword Removal: Removes common English stopwords while preserving meaningful terms such as:\n",
    "    \n",
    "        - Emotional/contextual words: \"not\", \"no\", \"never\", \"against\"\n",
    "        - Intensity indicators: \"very\", \"so\", \"too\", \"only\"\n",
    "        - Directional/spatial words: \"up\", \"down\", \"in\", \"out\"\n",
    "    \n",
    "    * Stemming:\n",
    "        - Applied Porter Stemmer to reduce words to their root form BUT after randomly peeking data, the results weren't good\n",
    "        - Switched to spacy\n",
    "\n",
    "5. Label Encoding\n",
    "\n",
    "    * Implements label encoding for emotion categories in training data\n",
    "    * Provides distribution statistics for emotion labels in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import emoji\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract emojis and count their occurrences\n",
    "def extract_emojis(text):\n",
    "    emoji_counter = Counter()\n",
    "    clean_text = \"\"\n",
    "    \n",
    "    for char in text:\n",
    "        if char in emoji.EMOJI_DATA:\n",
    "            emoji_counter[char] += 1\n",
    "        else:\n",
    "            clean_text += char\n",
    "            \n",
    "    return emoji_counter, clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    # 1. Extract and count emojis before preprocessing\n",
    "    emoji_counter, text = extract_emojis(text)\n",
    "    \n",
    "    # 2. Find uppercase words (words with 2 or more uppercase letters)\n",
    "    uppercase_words = re.findall(r'\\b[A-Z][A-Z]+\\b', text)\n",
    "    \n",
    "    # 3. Cleaning\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+', '', text)  # Remove mentions\n",
    "    text = re.sub(r'#\\w+', '', text)  # Remove hashtags completely\n",
    "    \n",
    "    # 4. Handle punctuation\n",
    "    text = re.sub(r'\\.{2,}', ' .... ', text)  # Convert multiple dots to ....\n",
    "    text = re.sub(r'!{2,}', ' !! ', text)     # Convert multiple ! to !!\n",
    "    text = re.sub(r'\\?{2,}', ' ?? ', text)    # Convert multiple ? to ??\n",
    "    text = re.sub(r'[^\\w\\s!?.]', ' ', text)   # Remove other punctuation\n",
    "    text = re.sub(r'\\s*\\.\\s*', ' ', text)     # Remove standalone periods\n",
    "    \n",
    "    # 5. Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # 6. Initialize tokens list\n",
    "    tokens = []\n",
    "    \n",
    "    # 7. Add base text tokens\n",
    "    tokens.extend(text.split())\n",
    "    \n",
    "    # 8. Add uppercase markers (excluding LH)\n",
    "    uppercase_tokens = [f\"uppercase_{word.lower()}\" for word in uppercase_words \n",
    "                       if word.lower() not in ['lh']]\n",
    "    tokens.extend(uppercase_tokens)\n",
    "    \n",
    "    # 9. Add emoji tokens with counts\n",
    "    for emoji_char, count in emoji_counter.items():\n",
    "        emoji_name = emoji.demojize(emoji_char).strip(':').replace('_', '')\n",
    "        if count > 1:\n",
    "            tokens.append(f\"emoji_{emoji_name}_{count}x\")\n",
    "        else:\n",
    "            tokens.append(f\"emoji_{emoji_name}\")\n",
    "    \n",
    "    # 10. Convert \"lh\" variations to consistent format\n",
    "    tokens = ['lh' if t in ['lh', '<lh>', 'LH', '<LH>'] else t for t in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, text_column='text'):\n",
    "    # Load spaCy model (needs: python -m spacy download en_core_web_sm)\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    \n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # 11. Missing values\n",
    "    df_processed = df_processed.assign(\n",
    "        **{text_column: df_processed[text_column].fillna('')}\n",
    "    )\n",
    "    \n",
    "    # 12. Clean text\n",
    "    df_processed['cleaned_text'] = df_processed[text_column].apply(preprocess_text)\n",
    "    \n",
    "    # 13. Stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Keep only very specific emotional/meaningful stopwords\n",
    "    keep_words = {\n",
    "        'not', 'no', 'never', 'against',\n",
    "        'very', 'so', 'too', 'only',\n",
    "        'up', 'down', 'in', 'out'\n",
    "    }\n",
    "    stop_words = stop_words - keep_words\n",
    "    \n",
    "    def tokenize_and_lemmatize(text):\n",
    "        tokens = text.split()\n",
    "        processed_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            # Skip special tokens and short words\n",
    "            if (any(token.startswith(prefix) for prefix in \n",
    "                ['emoji', 'uppercase']) or\n",
    "                token in ['lh', '!!', '??', '....'] or\n",
    "                len(token) <= 2):\n",
    "                processed_tokens.append(token)\n",
    "            # Lemmatize non-stopwords\n",
    "            elif token not in stop_words:\n",
    "                # Process with spaCy\n",
    "                doc = nlp(token)\n",
    "                lemma = doc[0].lemma_\n",
    "                processed_tokens.append(lemma)\n",
    "        \n",
    "        return ' '.join(processed_tokens)\n",
    "    \n",
    "    df_processed['processed_text'] = df_processed['cleaned_text'].apply(tokenize_and_lemmatize)\n",
    "    \n",
    "    # Encode labels (for training data)\n",
    "    if 'emotion' in df_processed.columns:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df_processed['emotion_encoded'] = label_encoder.fit_transform(df_processed['emotion'])\n",
    "        return df_processed, label_encoder\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process both training and test sets\n",
    "def process_train_test(train_df, test_df, text_column='text'):\n",
    "    processed_train, label_encoder = preprocess_data(train_df, text_column)\n",
    "    processed_test = preprocess_data(test_df, text_column)\n",
    "    \n",
    "    print(\"\\nPreprocessing Summary:\")\n",
    "    print(f\"Training samples: {len(processed_train)}\")\n",
    "    print(f\"Test samples: {len(processed_test)}\")\n",
    "    \n",
    "    if 'emotion' in processed_train.columns:\n",
    "        print(\"\\nTraining Set Label Distribution:\")\n",
    "        print(processed_train['emotion'].value_counts(normalize=True).round(3) * 100)\n",
    "    \n",
    "    return processed_train, processed_test, label_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly peek 10 samples in the preprocessed text to see the changes made to the original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  5  6 12  7] [ 9 49 37 35 46]\n",
      "\n",
      "Preprocessing Summary:\n",
      "Training samples: 5\n",
      "Test samples: 5\n",
      "\n",
      "Training Set Label Distribution:\n",
      "emotion\n",
      "anticipation    40.0\n",
      "joy             40.0\n",
      "anger           20.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "------TRAINING------\n",
      "\n",
      "Original vs Processed Text:\n",
      "\n",
      "Original: People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that's <LH>\n",
      "Processed: people post add me on must be dehydrate cuz man s lh\n",
      "\n",
      "Original: @RISKshow @TheKevinAllison Thx for the BEST TIME tonight. What stories! Heartbreakingly <LH> #authentic #LaughOutLoud good!!\n",
      "Processed: thx well time tonight story heartbreakingly lh good !! uppercase_best uppercase_time\n",
      "\n",
      "Original: Still waiting on those supplies Liscus. <LH>\n",
      "Processed: still wait on supply liscus lh\n",
      "\n",
      "Original: Can someone tell my why my feeds scroll back to the same 30 tweets that I saw 1 min ago? #Pissed!\n",
      "Processed: someone tell my my feed scroll back to 30 tweet i see 1 min ago !\n",
      "\n",
      "Original: Love knows no gender. 😢😭 <LH>\n",
      "Processed: love know no gender lh emoji_cryingface emoji_loudlycryingface\n",
      "\n",
      "------TEST------\n",
      "\n",
      "Original vs Processed Text:\n",
      "\n",
      "Original: When do you have enough ? When are you satisfied ? Is you goal really all about money ?  #materialism #money #possessions <LH>\n",
      "Processed: do enough ? satisfy ? is goal really money ? lh\n",
      "\n",
      "Original: @JulieChen when can we expect a season of #CelebrityBigBrother I think that would be <LH>\n",
      "Processed: we expect a season of i think would be lh\n",
      "\n",
      "Original: I like how Hayvens mommy, daddy, and the keyboard warriors have to jump into everything. She can’t handle anything herself. #sheltered <LH>\n",
      "Processed: i like hayven mommy daddy keyboard warrior to jump everything t handle anything lh\n",
      "\n",
      "Original: Turns out you can recognise people by their undies. <LH>\n",
      "Processed: turn out recognise people by undie lh\n",
      "\n",
      "Original: I just love it when every single one of my songs just delete themselves..😡😒 this is the 3rd times this has happened! <LH> #notamused\n",
      "Processed: i love it every single one of my song delete is 3rd time happen lh emoji_enragedface emoji_unamusedface\n"
     ]
    }
   ],
   "source": [
    "# Get 5 samples each\n",
    "random_indices1 = np.random.choice(processed_train.index, size=5, replace=False)\n",
    "random_indices2 = np.random.choice(processed_test.index, size=5, replace=False)\n",
    "print(random_indices1, random_indices2)\n",
    "train_df_samp = train_df.loc[random_indices1]\n",
    "test_df_samp = test_df.loc[random_indices2]\n",
    "processed_train, processed_test, label_encoder = process_train_test(train_df_samp, test_df_samp,'text')\n",
    "\n",
    "# Check sample of processed text\n",
    "print(\"\\n------TRAINING------\")\n",
    "print(\"\\nOriginal vs Processed Text:\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nOriginal: {processed_train['text'].iloc[i]}\")\n",
    "    print(f\"Processed: {processed_train['processed_text'].iloc[i]}\")\n",
    "print(\"\\n------TEST------\")\n",
    "print(\"\\nOriginal vs Processed Text:\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nOriginal: {processed_test['text'].iloc[i]}\")\n",
    "    print(f\"Processed: {processed_test['processed_text'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, preprocessed samples look good! Let's apply preprocessing techniques to the entire training & test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Summary:\n",
      "Training samples: 1455563\n",
      "Test samples: 411972\n",
      "\n",
      "Training Set Label Distribution:\n",
      "emotion\n",
      "joy             35.5\n",
      "anticipation    17.1\n",
      "trust           14.1\n",
      "sadness         13.3\n",
      "disgust          9.6\n",
      "fear             4.4\n",
      "surprise         3.3\n",
      "anger            2.7\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "------TRAINING------\n",
      "\n",
      "Original vs Processed Text:\n",
      "\n",
      "Original: People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that's <LH>\n",
      "Processed: people post add me on must be dehydrate cuz man s lh\n",
      "\n",
      "Original: @brianklaas As we see, Trump is dangerous to #freepress around the world. What a <LH> <LH> #TrumpLegacy.  #CNN\n",
      "Processed: as we see trump is dangerous to around world a lh lh uppercase_cnn\n",
      "\n",
      "Original: Now ISSA is stalking Tasha 😂😂😂 <LH>\n",
      "Processed: issa is stalk tasha lh uppercase_issa emoji_facewithtearsofjoy_3x\n",
      "\n",
      "Original: @RISKshow @TheKevinAllison Thx for the BEST TIME tonight. What stories! Heartbreakingly <LH> #authentic #LaughOutLoud good!!\n",
      "Processed: thx well time tonight story heartbreakingly lh good !! uppercase_best uppercase_time\n",
      "\n",
      "Original: Still waiting on those supplies Liscus. <LH>\n",
      "Processed: still wait on supply liscus lh\n",
      "\n",
      "------TEST------\n",
      "\n",
      "Original vs Processed Text:\n",
      "\n",
      "Original: Confident of your obedience, I write to you, knowing that you will do even more than I ask. (Philemon 1:21) 3/4 #bibleverse <LH> <LH>\n",
      "Processed: confident of obedience i write to know do even i ask philemon 1 21 3 4 lh lh\n",
      "\n",
      "Original: \"Trust is not the same as faith. A friend is someone you trust. Putting faith in anyone is a mistake.\" ~ Christopher Hitchens <LH> <LH>\n",
      "Processed: trust is not as faith a friend is someone trust put faith in anyone is a mistake christopher hitchen lh lh\n",
      "\n",
      "Original: When do you have enough ? When are you satisfied ? Is you goal really all about money ?  #materialism #money #possessions <LH>\n",
      "Processed: do enough ? satisfy ? is goal really money ? lh\n",
      "\n",
      "Original: God woke you up, now chase the day #GodsPlan #GodsWork <LH>\n",
      "Processed: god wake up chase day lh\n",
      "\n",
      "Original: In these tough times, who do YOU turn to as your symbol of hope? <LH>\n",
      "Processed: in tough time do turn to as symbol of hope lh uppercase_you\n"
     ]
    }
   ],
   "source": [
    "processed_train, processed_test, label_encoder = process_train_test(train_df, test_df,'text')\n",
    "\n",
    "# Check sample of processed text\n",
    "print(\"\\n------TRAINING------\")\n",
    "print(\"\\nOriginal vs Processed Text:\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nOriginal: {processed_train['text'].iloc[i]}\")\n",
    "    print(f\"Processed: {processed_train['processed_text'].iloc[i]}\")\n",
    "print(\"\\n------TEST------\")\n",
    "print(\"\\nOriginal vs Processed Text:\")\n",
    "for i in range(5):\n",
    "    print(f\"\\nOriginal: {processed_test['text'].iloc[i]}\")\n",
    "    print(f\"Processed: {processed_test['processed_text'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the processed text with the hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original: People who post \"add me on #Snapchat\" must be dehydrated. Cuz man.... that's <LH>\n",
      "Processed: people post add me on must be dehydrate cuz man s lh Snapchat\n",
      "\n",
      "Original: @brianklaas As we see, Trump is dangerous to #freepress around the world. What a <LH> <LH> #TrumpLegacy.  #CNN\n",
      "Processed: as we see trump is dangerous to around world a lh lh uppercase_cnn freepress TrumpLegacy CNN\n",
      "\n",
      "Original: Now ISSA is stalking Tasha 😂😂😂 <LH>\n",
      "Processed: issa is stalk tasha lh uppercase_issa emoji_facewithtearsofjoy_3x\n",
      "\n",
      "Original: @RISKshow @TheKevinAllison Thx for the BEST TIME tonight. What stories! Heartbreakingly <LH> #authentic #LaughOutLoud good!!\n",
      "Processed: thx well time tonight story heartbreakingly lh good !! uppercase_best uppercase_time authentic LaughOutLoud\n",
      "\n",
      "Original: Still waiting on those supplies Liscus. <LH>\n",
      "Processed: still wait on supply liscus lh\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "processed_train['final_text'] = processed_train.apply(\n",
    "    lambda row: row['processed_text'] + ' ' + ' '.join(row['hashtags']) if row['hashtags'] else row['processed_text'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nOriginal: {processed_train['text'].iloc[i]}\")\n",
    "    print(f\"Processed: {processed_train['final_text'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original: Confident of your obedience, I write to you, knowing that you will do even more than I ask. (Philemon 1:21) 3/4 #bibleverse <LH> <LH>\n",
      "Processed: confident of obedience i write to know do even i ask philemon 1 21 3 4 lh lh bibleverse\n",
      "\n",
      "Original: \"Trust is not the same as faith. A friend is someone you trust. Putting faith in anyone is a mistake.\" ~ Christopher Hitchens <LH> <LH>\n",
      "Processed: trust is not as faith a friend is someone trust put faith in anyone is a mistake christopher hitchen lh lh\n",
      "\n",
      "Original: When do you have enough ? When are you satisfied ? Is you goal really all about money ?  #materialism #money #possessions <LH>\n",
      "Processed: do enough ? satisfy ? is goal really money ? lh materialism money possessions\n",
      "\n",
      "Original: God woke you up, now chase the day #GodsPlan #GodsWork <LH>\n",
      "Processed: god wake up chase day lh GodsPlan GodsWork\n",
      "\n",
      "Original: In these tough times, who do YOU turn to as your symbol of hope? <LH>\n",
      "Processed: in tough time do turn to as symbol of hope lh uppercase_you\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "processed_test['final_text'] = processed_test.apply(\n",
    "    lambda row: row['processed_text'] + ' ' + ' '.join(row['hashtags']) if row['hashtags'] else row['processed_text'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"\\nOriginal: {processed_test['text'].iloc[i]}\")\n",
    "    print(f\"Processed: {processed_test['final_text'].iloc[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>emotion_encoded</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x376b20</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>people who post add me on must be dehydrated c...</td>\n",
       "      <td>people post add me on must be dehydrate cuz ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>people post add me on must be dehydrate cuz ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>as we see trump is dangerous to around the wor...</td>\n",
       "      <td>as we see trump is dangerous to around world a...</td>\n",
       "      <td>5</td>\n",
       "      <td>as we see trump is dangerous to around world a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Now ISSA is stalking Tasha 😂😂😂 &lt;LH&gt;</td>\n",
       "      <td>fear</td>\n",
       "      <td>now issa is stalking tasha lh uppercase_issa e...</td>\n",
       "      <td>issa is stalk tasha lh uppercase_issa emoji_fa...</td>\n",
       "      <td>3</td>\n",
       "      <td>issa is stalk tasha lh uppercase_issa emoji_fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x1d755c</td>\n",
       "      <td>[authentic, LaughOutLoud]</td>\n",
       "      <td>@RISKshow @TheKevinAllison Thx for the BEST TI...</td>\n",
       "      <td>joy</td>\n",
       "      <td>thx for the best time tonight what stories! he...</td>\n",
       "      <td>thx well time tonight story heartbreakingly lh...</td>\n",
       "      <td>4</td>\n",
       "      <td>thx well time tonight story heartbreakingly lh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0x2c91a8</td>\n",
       "      <td>[]</td>\n",
       "      <td>Still waiting on those supplies Liscus. &lt;LH&gt;</td>\n",
       "      <td>anticipation</td>\n",
       "      <td>still waiting on those supplies liscus lh</td>\n",
       "      <td>still wait on supply liscus lh</td>\n",
       "      <td>1</td>\n",
       "      <td>still wait on supply liscus lh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id                       hashtags  \\\n",
       "0  0x376b20                     [Snapchat]   \n",
       "1  0x2d5350  [freepress, TrumpLegacy, CNN]   \n",
       "3  0x1cd5b0                             []   \n",
       "5  0x1d755c      [authentic, LaughOutLoud]   \n",
       "6  0x2c91a8                             []   \n",
       "\n",
       "                                                text       emotion  \\\n",
       "0  People who post \"add me on #Snapchat\" must be ...  anticipation   \n",
       "1  @brianklaas As we see, Trump is dangerous to #...       sadness   \n",
       "3                Now ISSA is stalking Tasha 😂😂😂 <LH>          fear   \n",
       "5  @RISKshow @TheKevinAllison Thx for the BEST TI...           joy   \n",
       "6       Still waiting on those supplies Liscus. <LH>  anticipation   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  people who post add me on must be dehydrated c...   \n",
       "1  as we see trump is dangerous to around the wor...   \n",
       "3  now issa is stalking tasha lh uppercase_issa e...   \n",
       "5  thx for the best time tonight what stories! he...   \n",
       "6          still waiting on those supplies liscus lh   \n",
       "\n",
       "                                      processed_text  emotion_encoded  \\\n",
       "0  people post add me on must be dehydrate cuz ma...                1   \n",
       "1  as we see trump is dangerous to around world a...                5   \n",
       "3  issa is stalk tasha lh uppercase_issa emoji_fa...                3   \n",
       "5  thx well time tonight story heartbreakingly lh...                4   \n",
       "6                     still wait on supply liscus lh                1   \n",
       "\n",
       "                                          final_text  \n",
       "0  people post add me on must be dehydrate cuz ma...  \n",
       "1  as we see trump is dangerous to around world a...  \n",
       "3  issa is stalk tasha lh uppercase_issa emoji_fa...  \n",
       "5  thx well time tonight story heartbreakingly lh...  \n",
       "6                     still wait on supply liscus lh  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>final_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x28b412</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "      <td>confident of your obedience i write to you kno...</td>\n",
       "      <td>confident of obedience i write to know do even...</td>\n",
       "      <td>confident of obedience i write to know do even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2de201</td>\n",
       "      <td>[]</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "      <td>trust is not the same as faith a friend is som...</td>\n",
       "      <td>trust is not as faith a friend is someone trus...</td>\n",
       "      <td>trust is not as faith a friend is someone trus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0x218443</td>\n",
       "      <td>[materialism, money, possessions]</td>\n",
       "      <td>When do you have enough ? When are you satisfi...</td>\n",
       "      <td>when do you have enough ? when are you satisfi...</td>\n",
       "      <td>do enough ? satisfy ? is goal really money ? lh</td>\n",
       "      <td>do enough ? satisfy ? is goal really money ? l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0x2939d5</td>\n",
       "      <td>[GodsPlan, GodsWork]</td>\n",
       "      <td>God woke you up, now chase the day #GodsPlan #...</td>\n",
       "      <td>god woke you up now chase the day lh</td>\n",
       "      <td>god wake up chase day lh</td>\n",
       "      <td>god wake up chase day lh GodsPlan GodsWork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0x26289a</td>\n",
       "      <td>[]</td>\n",
       "      <td>In these tough times, who do YOU turn to as yo...</td>\n",
       "      <td>in these tough times who do you turn to as you...</td>\n",
       "      <td>in tough time do turn to as symbol of hope lh ...</td>\n",
       "      <td>in tough time do turn to as symbol of hope lh ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id                           hashtags  \\\n",
       "2   0x28b412                       [bibleverse]   \n",
       "4   0x2de201                                 []   \n",
       "9   0x218443  [materialism, money, possessions]   \n",
       "30  0x2939d5               [GodsPlan, GodsWork]   \n",
       "33  0x26289a                                 []   \n",
       "\n",
       "                                                 text  \\\n",
       "2   Confident of your obedience, I write to you, k...   \n",
       "4   \"Trust is not the same as faith. A friend is s...   \n",
       "9   When do you have enough ? When are you satisfi...   \n",
       "30  God woke you up, now chase the day #GodsPlan #...   \n",
       "33  In these tough times, who do YOU turn to as yo...   \n",
       "\n",
       "                                         cleaned_text  \\\n",
       "2   confident of your obedience i write to you kno...   \n",
       "4   trust is not the same as faith a friend is som...   \n",
       "9   when do you have enough ? when are you satisfi...   \n",
       "30               god woke you up now chase the day lh   \n",
       "33  in these tough times who do you turn to as you...   \n",
       "\n",
       "                                       processed_text  \\\n",
       "2   confident of obedience i write to know do even...   \n",
       "4   trust is not as faith a friend is someone trus...   \n",
       "9     do enough ? satisfy ? is goal really money ? lh   \n",
       "30                           god wake up chase day lh   \n",
       "33  in tough time do turn to as symbol of hope lh ...   \n",
       "\n",
       "                                           final_text  \n",
       "2   confident of obedience i write to know do even...  \n",
       "4   trust is not as faith a friend is someone trus...  \n",
       "9   do enough ? satisfy ? is goal really money ? l...  \n",
       "30         god wake up chase day lh GodsPlan GodsWork  \n",
       "33  in tough time do turn to as symbol of hope lh ...  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save datasets (Rather than executing all the cells again, just load them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train.to_csv(\"processed_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test.to_csv(\"processed_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" If need to load dataset\"\"\"\n",
    "X_train = pd.read_csv('processed_train.csv')\n",
    "X_test = pd.read_csv('processed_test.csv')\n",
    "\n",
    "y_train = X_train['emotion_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of your DataFrames before processing\n",
    "X_train = processed_train.reset_index(drop=True)\n",
    "X_test = processed_test.reset_index(drop=True)\n",
    "\n",
    "y_train = processed_train['emotion_encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing \"final_text\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [tweet_id, hashtags, text, cleaned_text, processed_text, final_text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "\n",
    "nan_rows_test = X_test[X_test['final_text'].isna()]\n",
    "print(nan_rows_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         tweet_id hashtags                                          text  \\\n",
      "695716   0x32dd39       []  @Dpugel @onceuponA But...but...but...#broken   \n",
      "1338255  0x353b03       []            @TheBoss_WWE Same here......#crazy   \n",
      "\n",
      "          emotion cleaned_text processed_text  emotion_encoded final_text  \n",
      "695716    sadness  but but but            NaN                5        NaN  \n",
      "1338255  surprise    same here            NaN                6        NaN  \n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "nan_rows_train = X_train[X_train['final_text'].isna()]\n",
    "print(nan_rows_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [tweet_id, hashtags, text, emotion, cleaned_text, processed_text, emotion_encoded, final_text]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "X_train_cleaned = X_train.dropna(subset=['final_text'])\n",
    "\n",
    "# Check if rows with missing values have been dropped\n",
    "nan_rows_train = X_train_cleaned[X_train_cleaned['final_text'].isna()]\n",
    "print(nan_rows_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_cleaned['final_text'])\n",
    "X_test_tfidf = vectorizer.transform(X_train_cleaned['final_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import save_npz\n",
    "\n",
    "save_npz(\"X_train_tfidf.npz\", X_train_tfidf)\n",
    "save_npz(\"X_test_tfidf.npz\", X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "# load the numpy arrays\n",
    "X_train_tfidf = load_npz(\"X_train_tfidf.npz\")\n",
    "X_test_tfidf = load_npz(\"X_test_tfidf.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Python\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load BERT model\n",
    "bert_model = SentenceTransformer('paraphrase-MiniLM-L6-v2') # smaller and faster\n",
    "\n",
    "# 2. Convert text to embeddings\n",
    "X_train_bert = bert_model.encode(X_train['final_text'])\n",
    "X_test_bert = bert_model.encode(X_test['final_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save numpy arrays\n",
    "np.save(\"X_train_bert.npy\", X_train_bert)\n",
    "np.save(\"X_test_bert.npy\", X_test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the numpy arrays\n",
    "X_train_bert = np.load(\"X_train_bert.npy\")\n",
    "X_test_bert = np.load(\"X_test_bert.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 384)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bert.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Random Forest + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## build RandomForest model\n",
    "RF_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "## training!\n",
    "RF_model = RF_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'sadness', ..., 'anticipation', 'anticipation',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "## predict!\n",
    "y_train_pred_rf0 = RF_model.predict(X_train_tfidf)\n",
    "y_test_pred_rf0 = RF_model.predict(X_test_tfidf)\n",
    "\n",
    "train_accuracy_rf0 = accuracy_score(y_train, y_train_pred_rf0)\n",
    "\n",
    "predictions_labels_rf0 = label_encoder.inverse_transform(y_test_pred_rf0)\n",
    "predictions_labels_rf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932880266948253\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_rf0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.36544"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Random Forest + Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training!\n",
    "RF_model = RF_model.fit(X_train_bert, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'trust', 'joy', ..., 'joy', 'joy', 'joy'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "y_train_pred_rf1 = RF_model.predict(X_train_bert)\n",
    "y_test_pred_rf1 = RF_model.predict(X_test_bert)\n",
    "\n",
    "train_accuracy_rf1 = accuracy_score(y_train, y_train_pred_rf1)\n",
    "\n",
    "predictions_labels_rf1 = label_encoder.inverse_transform(y_test_pred_rf1)\n",
    "predictions_labels_rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9942475866726483\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_rf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.32234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Neural Network + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "## build neural network model\n",
    "NN_model = MLPClassifier(hidden_layer_sizes=(100, 50), \n",
    "              activation='relu', \n",
    "              solver='adam', \n",
    "              max_iter=500, \n",
    "              random_state=42, \n",
    "              early_stopping=True, \n",
    "              validation_fraction=0.1)\n",
    "## training!\n",
    "NN_model = NN_model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'sadness', ..., 'sadness', 'joy',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "y_train_pred_nn0 = NN_model.predict(X_train_tfidf)\n",
    "y_test_pred_nn0 = NN_model.predict(X_test_tfidf)\n",
    "\n",
    "train_accuracy_nn0 = accuracy_score(y_train, y_train_pred_nn0)\n",
    "\n",
    "predictions_labels_nn0 = label_encoder.inverse_transform(y_test_pred_nn0)\n",
    "predictions_labels_nn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5200139052723929\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_nn0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.38505"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Neural Network + Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training!\n",
    "NN_model = NN_model.fit(X_train_bert, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'trust', 'joy', ..., 'sadness', 'joy', 'sadness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "y_train_pred_nn1 = NN_model.predict(X_train_bert)\n",
    "y_test_pred_nn1 = NN_model.predict(X_test_bert)\n",
    "\n",
    "train_accuracy_nn1 = accuracy_score(y_train, y_train_pred_nn1)\n",
    "\n",
    "predictions_labels_nn1 = label_encoder.inverse_transform(y_test_pred_nn1)\n",
    "predictions_labels_nn1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5325066658056024\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_nn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.41135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network + Transformer performed best, now increase the model's capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.38016811\n",
      "Validation score: 0.502671\n",
      "Iteration 2, loss = 1.32220391\n",
      "Validation score: 0.514594\n",
      "Iteration 3, loss = 1.30030137\n",
      "Validation score: 0.520722\n",
      "Iteration 4, loss = 1.28565209\n",
      "Validation score: 0.522069\n",
      "Iteration 5, loss = 1.27492459\n",
      "Validation score: 0.522100\n",
      "Iteration 6, loss = 1.26641573\n",
      "Validation score: 0.523402\n",
      "Iteration 7, loss = 1.25885067\n",
      "Validation score: 0.525384\n",
      "Iteration 8, loss = 1.25296589\n",
      "Validation score: 0.525548\n",
      "Iteration 9, loss = 1.24771370\n",
      "Validation score: 0.525037\n",
      "Iteration 10, loss = 1.24326306\n",
      "Validation score: 0.526692\n",
      "Iteration 11, loss = 1.23898989\n",
      "Validation score: 0.525944\n",
      "Iteration 12, loss = 1.23520598\n",
      "Validation score: 0.525566\n",
      "Iteration 13, loss = 1.23150582\n",
      "Validation score: 0.526672\n",
      "Iteration 14, loss = 1.22831809\n",
      "Validation score: 0.524669\n",
      "Iteration 15, loss = 1.22526027\n",
      "Validation score: 0.525700\n",
      "Iteration 16, loss = 1.22269792\n",
      "Validation score: 0.525844\n",
      "Iteration 17, loss = 1.22031525\n",
      "Validation score: 0.526442\n",
      "Iteration 18, loss = 1.21790131\n",
      "Validation score: 0.526236\n",
      "Iteration 19, loss = 1.21555282\n",
      "Validation score: 0.525305\n",
      "Iteration 20, loss = 1.21398536\n",
      "Validation score: 0.524298\n",
      "Iteration 21, loss = 1.21134729\n",
      "Validation score: 0.522512\n",
      "Iteration 22, loss = 1.20997354\n",
      "Validation score: 0.523965\n",
      "Iteration 23, loss = 1.20789706\n",
      "Validation score: 0.524813\n",
      "Iteration 24, loss = 1.20636988\n",
      "Validation score: 0.524631\n",
      "Iteration 25, loss = 1.20459504\n",
      "Validation score: 0.524525\n",
      "Iteration 26, loss = 1.20310496\n",
      "Validation score: 0.523759\n",
      "Iteration 27, loss = 1.20182021\n",
      "Validation score: 0.524381\n",
      "Iteration 28, loss = 1.20044053\n",
      "Validation score: 0.522594\n",
      "Iteration 29, loss = 1.19884745\n",
      "Validation score: 0.522289\n",
      "Iteration 30, loss = 1.19789551\n",
      "Validation score: 0.522629\n",
      "Iteration 31, loss = 1.19676624\n",
      "Validation score: 0.524123\n",
      "Validation score did not improve more than tol=0.000100 for 20 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 128, 64),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=1000, n_iter_no_change=20,\n",
       "              random_state=42, validation_fraction=0.2, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 128, 64),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=1000, n_iter_no_change=20,\n",
       "              random_state=42, validation_fraction=0.2, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 128, 64),\n",
       "              learning_rate='adaptive', max_iter=1000, n_iter_no_change=20,\n",
       "              random_state=42, validation_fraction=0.2, verbose=True)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# First, let's scale the BERT embeddings\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_bert)\n",
    "X_test_scaled = scaler.transform(X_test_bert)\n",
    "\n",
    "# Neural network with more complex architecture\n",
    "improved_NN = MLPClassifier(\n",
    "    hidden_layer_sizes=(256, 128, 64),  \n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,  \n",
    "    batch_size='auto',\n",
    "    learning_rate='adaptive',  \n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,  \n",
    "    tol=1e-4,\n",
    "    random_state=42,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.2,  \n",
    "    beta_1=0.9,  \n",
    "    beta_2=0.999,  \n",
    "    n_iter_no_change=20,  \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "## training!\n",
    "improved_NN.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'trust', 'anticipation', ..., 'sadness', 'joy',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "y_train_pred_nn2 = improved_NN.predict(X_train_scaled)\n",
    "y_test_pred_nn2 = improved_NN.predict(X_test_scaled)\n",
    "\n",
    "train_accuracy_nn2 = accuracy_score(y_train, y_train_pred_nn2)\n",
    "\n",
    "predictions_labels_nn2 = label_encoder.inverse_transform(y_test_pred_nn2)\n",
    "predictions_labels_nn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5476032298155422\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_nn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.42176"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try More Complex Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural network model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# First, let's scale the BERT embeddings\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_bert)\n",
    "X_test_scaled = scaler.transform(X_test_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.40869631\n",
      "Validation score: 0.498976\n",
      "Iteration 2, loss = 1.35536033\n",
      "Validation score: 0.506694\n",
      "Iteration 3, loss = 1.33657093\n",
      "Validation score: 0.506236\n",
      "Iteration 4, loss = 1.32506570\n",
      "Validation score: 0.512295\n",
      "Iteration 5, loss = 1.31708895\n",
      "Validation score: 0.512424\n",
      "Iteration 6, loss = 1.31075426\n",
      "Validation score: 0.511017\n",
      "Iteration 7, loss = 1.30527514\n",
      "Validation score: 0.514764\n",
      "Iteration 8, loss = 1.30041137\n",
      "Validation score: 0.510921\n",
      "Iteration 9, loss = 1.29674029\n",
      "Validation score: 0.509236\n",
      "Iteration 10, loss = 1.29327380\n",
      "Validation score: 0.513514\n",
      "Iteration 11, loss = 1.29028881\n",
      "Validation score: 0.511563\n",
      "Iteration 12, loss = 1.28730029\n",
      "Validation score: 0.513582\n",
      "Iteration 13, loss = 1.28493261\n",
      "Validation score: 0.510408\n",
      "Iteration 14, loss = 1.28260045\n",
      "Validation score: 0.511792\n",
      "Iteration 15, loss = 1.28081525\n",
      "Validation score: 0.514663\n",
      "Iteration 16, loss = 1.27892733\n",
      "Validation score: 0.510601\n",
      "Iteration 17, loss = 1.27629815\n",
      "Validation score: 0.512694\n",
      "Iteration 18, loss = 1.27477865\n",
      "Validation score: 0.512992\n",
      "Iteration 19, loss = 1.27280767\n",
      "Validation score: 0.513834\n",
      "Iteration 20, loss = 1.27137678\n",
      "Validation score: 0.510253\n",
      "Iteration 21, loss = 1.26969968\n",
      "Validation score: 0.510578\n",
      "Iteration 22, loss = 1.26844015\n",
      "Validation score: 0.510903\n",
      "Iteration 23, loss = 1.26704982\n",
      "Validation score: 0.513248\n",
      "Iteration 24, loss = 1.26567907\n",
      "Validation score: 0.510798\n",
      "Iteration 25, loss = 1.26437396\n",
      "Validation score: 0.511320\n",
      "Iteration 26, loss = 1.26343113\n",
      "Validation score: 0.510701\n",
      "Iteration 27, loss = 1.26226421\n",
      "Validation score: 0.507926\n",
      "Iteration 28, loss = 1.26058939\n",
      "Validation score: 0.511155\n",
      "Iteration 29, loss = 1.25965670\n",
      "Validation score: 0.509584\n",
      "Iteration 30, loss = 1.25893851\n",
      "Validation score: 0.508045\n",
      "Iteration 31, loss = 1.25782773\n",
      "Validation score: 0.508897\n",
      "Iteration 32, loss = 1.25707194\n",
      "Validation score: 0.512369\n",
      "Iteration 33, loss = 1.25596330\n",
      "Validation score: 0.507953\n",
      "Iteration 34, loss = 1.25491975\n",
      "Validation score: 0.511137\n",
      "Iteration 35, loss = 1.25398085\n",
      "Validation score: 0.507092\n",
      "Iteration 36, loss = 1.25291738\n",
      "Validation score: 0.510234\n",
      "Iteration 37, loss = 1.25172735\n",
      "Validation score: 0.507921\n",
      "Iteration 38, loss = 1.25126157\n",
      "Validation score: 0.505856\n",
      "Iteration 39, loss = 1.25064135\n",
      "Validation score: 0.507193\n",
      "Iteration 40, loss = 1.24931174\n",
      "Validation score: 0.506584\n",
      "Iteration 41, loss = 1.24850217\n",
      "Validation score: 0.508705\n",
      "Iteration 42, loss = 1.24765754\n",
      "Validation score: 0.506053\n",
      "Iteration 43, loss = 1.24729328\n",
      "Validation score: 0.509263\n",
      "Iteration 44, loss = 1.24707846\n",
      "Validation score: 0.508311\n",
      "Iteration 45, loss = 1.24582026\n",
      "Validation score: 0.506469\n",
      "Iteration 46, loss = 1.24513628\n",
      "Validation score: 0.509501\n",
      "Iteration 47, loss = 1.24364919\n",
      "Validation score: 0.508425\n",
      "Iteration 48, loss = 1.24422274\n",
      "Validation score: 0.506515\n",
      "Iteration 49, loss = 1.24292082\n",
      "Validation score: 0.503758\n",
      "Iteration 50, loss = 1.24212676\n",
      "Validation score: 0.503327\n",
      "Iteration 51, loss = 1.24194358\n",
      "Validation score: 0.505897\n",
      "Iteration 52, loss = 1.24102269\n",
      "Validation score: 0.505329\n",
      "Iteration 53, loss = 1.24134997\n",
      "Validation score: 0.506643\n",
      "Iteration 54, loss = 1.24016559\n",
      "Validation score: 0.502398\n",
      "Iteration 55, loss = 1.23971336\n",
      "Validation score: 0.506218\n",
      "Iteration 56, loss = 1.23943561\n",
      "Validation score: 0.502228\n",
      "Iteration 57, loss = 1.23861888\n",
      "Validation score: 0.505269\n",
      "Iteration 58, loss = 1.23793019\n",
      "Validation score: 0.506341\n",
      "Validation score did not improve more than tol=0.000010 for 50 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.0005, batch_size=64,\n",
       "              early_stopping=True, hidden_layer_sizes=(512, 256, 128),\n",
       "              learning_rate_init=0.0005, max_iter=2000, n_iter_no_change=50,\n",
       "              random_state=42, tol=1e-05, validation_fraction=0.15,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.0005, batch_size=64,\n",
       "              early_stopping=True, hidden_layer_sizes=(512, 256, 128),\n",
       "              learning_rate_init=0.0005, max_iter=2000, n_iter_no_change=50,\n",
       "              random_state=42, tol=1e-05, validation_fraction=0.15,\n",
       "              verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=0.0005, batch_size=64,\n",
       "              early_stopping=True, hidden_layer_sizes=(512, 256, 128),\n",
       "              learning_rate_init=0.0005, max_iter=2000, n_iter_no_change=50,\n",
       "              random_state=42, tol=1e-05, validation_fraction=0.15,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network with more complex architecture\n",
    "optimized_NN = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256, 128),\n",
    "    activation='tanh',\n",
    "    solver='adam',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.0005,  \n",
    "    alpha=0.0005,  \n",
    "    batch_size=64,\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.15,\n",
    "    n_iter_no_change=50, \n",
    "    tol=0.00001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "## training!\n",
    "optimized_NN.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'anticipation', ..., 'sadness',\n",
       "       'joy', 'sadness'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "## predict!\n",
    "y_train_pred_nn3 = optimized_NN.predict(X_train_scaled)\n",
    "y_test_pred_nn3 = optimized_NN.predict(X_test_scaled)\n",
    "\n",
    "train_accuracy_nn3 = accuracy_score(y_train, y_train_pred_nn3)\n",
    "\n",
    "predictions_labels_nn3 = label_encoder.inverse_transform(y_test_pred_nn3)\n",
    "predictions_labels_nn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5382597661523411\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_nn3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.40585"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural network model #2 via keras - Apply sample weights (due to imbalanced class distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 3ms/step - accuracy: 0.3703 - loss: 1.6686 - val_accuracy: 0.4120 - val_loss: 1.5595\n",
      "Epoch 2/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - accuracy: 0.4146 - loss: 1.5606 - val_accuracy: 0.4144 - val_loss: 1.5454\n",
      "Epoch 3/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3ms/step - accuracy: 0.4206 - loss: 1.5359 - val_accuracy: 0.4358 - val_loss: 1.5286\n",
      "Epoch 4/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - accuracy: 0.4256 - loss: 1.5218 - val_accuracy: 0.4314 - val_loss: 1.5371\n",
      "Epoch 5/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - accuracy: 0.4297 - loss: 1.5065 - val_accuracy: 0.4328 - val_loss: 1.5076\n",
      "Epoch 6/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - accuracy: 0.4315 - loss: 1.4972 - val_accuracy: 0.4301 - val_loss: 1.5046\n",
      "Epoch 7/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - accuracy: 0.4332 - loss: 1.4879 - val_accuracy: 0.4128 - val_loss: 1.5533\n",
      "Epoch 8/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3ms/step - accuracy: 0.4343 - loss: 1.4796 - val_accuracy: 0.4227 - val_loss: 1.5391\n",
      "Epoch 9/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 3ms/step - accuracy: 0.4361 - loss: 1.4754 - val_accuracy: 0.4176 - val_loss: 1.5404\n",
      "Epoch 10/10\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3ms/step - accuracy: 0.4361 - loss: 1.4700 - val_accuracy: 0.4195 - val_loss: 1.5490\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Neural network with balanced class weights\n",
    "# Samples from minority classes (e.g., anger) get higher weights\n",
    "# Samples from majority classes (e.g., joy) get lower weights\n",
    "\n",
    "# class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# create model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model with class weights\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                   class_weight=class_weight_dict,\n",
    "                   batch_size=64,\n",
    "                   epochs=10,\n",
    "                   validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43480992317199707\n",
      "\u001b[1m12875/12875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['trust', 'trust', 'anticipation', ..., 'sadness', 'trust', 'anger'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "train_accuracy = history.history['accuracy']\n",
    "train_accuracy_nn4 = train_accuracy[-1]  # gets the last epoch's accuracy\n",
    "print(train_accuracy_nn4)\n",
    "\n",
    "# predict!\n",
    "\n",
    "# get raw probabilities\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "\n",
    "# convert to class predictions (gets the class with highest probability)\n",
    "y_test_pred_nn4 = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "predictions_labels_nn4 = label_encoder.inverse_transform(y_test_pred_nn4)\n",
    "predictions_labels_nn4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.35244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural network model #3 via keras - Apply dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4ms/step - accuracy: 0.3594 - loss: 1.6909 - val_accuracy: 0.4113 - val_loss: 1.5830\n",
      "Epoch 2/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3ms/step - accuracy: 0.3968 - loss: 1.5982 - val_accuracy: 0.3887 - val_loss: 1.5849\n",
      "Epoch 3/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3ms/step - accuracy: 0.4034 - loss: 1.5834 - val_accuracy: 0.4218 - val_loss: 1.5473\n",
      "Epoch 4/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3ms/step - accuracy: 0.4043 - loss: 1.5708 - val_accuracy: 0.4250 - val_loss: 1.5414\n",
      "Epoch 5/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3ms/step - accuracy: 0.4075 - loss: 1.5584 - val_accuracy: 0.4230 - val_loss: 1.5527\n",
      "Epoch 6/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3ms/step - accuracy: 0.4091 - loss: 1.5529 - val_accuracy: 0.4182 - val_loss: 1.5410\n",
      "Epoch 7/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3ms/step - accuracy: 0.4087 - loss: 1.5495 - val_accuracy: 0.4199 - val_loss: 1.5315\n",
      "Epoch 8/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 3ms/step - accuracy: 0.4106 - loss: 1.5446 - val_accuracy: 0.4338 - val_loss: 1.5136\n",
      "Epoch 9/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 3ms/step - accuracy: 0.4114 - loss: 1.5410 - val_accuracy: 0.4329 - val_loss: 1.5360\n",
      "Epoch 10/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3ms/step - accuracy: 0.4150 - loss: 1.5348 - val_accuracy: 0.4160 - val_loss: 1.5425\n",
      "Epoch 11/20\n",
      "\u001b[1m19332/19332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 3ms/step - accuracy: 0.4132 - loss: 1.5315 - val_accuracy: 0.4221 - val_loss: 1.5282\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Neural network with balanced class weights\n",
    "# Samples from minority classes (e.g., anger) get higher weights\n",
    "# Samples from majority classes (e.g., joy) get lower weights\n",
    "\n",
    "# class weights\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(zip(np.unique(y_train), class_weights))\n",
    "\n",
    "# nn model\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.1),  \n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.1), \n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Add early stopping to prevent degradation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                   class_weight=class_weight_dict,\n",
    "                   batch_size=64,  \n",
    "                   epochs=20,\n",
    "                   validation_split=0.15,\n",
    "                   callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4119337797164917\n",
      "\u001b[1m12875/12875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'trust', 'anticipation', ..., 'disgust', 'joy',\n",
       "       'anger'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "train_accuracy = history.history['accuracy']\n",
    "train_accuracy_nn4 = train_accuracy[-1]  # gets the last epoch's accuracy\n",
    "print(train_accuracy_nn4)\n",
    "\n",
    "# predict!\n",
    "\n",
    "# get raw probabilities\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "\n",
    "# convert to class predictions (gets the class with highest probability)\n",
    "y_test_pred_nn4 = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "predictions_labels_nn4 = label_encoder.inverse_transform(y_test_pred_nn4)\n",
    "predictions_labels_nn4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.35244"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: seems like applying sample weights result to significantly low test accuracy, now let's just try more complex neural models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural network model #4 via keras - Try other complex models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 9ms/step - accuracy: 0.4563 - loss: 1.4855 - val_accuracy: 0.5042 - val_loss: 1.3488 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 5ms/step - accuracy: 0.4964 - loss: 1.3747 - val_accuracy: 0.5129 - val_loss: 1.3240 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 5ms/step - accuracy: 0.5045 - loss: 1.3532 - val_accuracy: 0.5182 - val_loss: 1.3109 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 5ms/step - accuracy: 0.5093 - loss: 1.3395 - val_accuracy: 0.5196 - val_loss: 1.3063 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 5ms/step - accuracy: 0.5133 - loss: 1.3313 - val_accuracy: 0.5227 - val_loss: 1.3006 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 5ms/step - accuracy: 0.5154 - loss: 1.3246 - val_accuracy: 0.5245 - val_loss: 1.2956 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 5ms/step - accuracy: 0.5183 - loss: 1.3179 - val_accuracy: 0.5255 - val_loss: 1.2929 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 5ms/step - accuracy: 0.5199 - loss: 1.3119 - val_accuracy: 0.5265 - val_loss: 1.2911 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 5ms/step - accuracy: 0.5214 - loss: 1.3067 - val_accuracy: 0.5285 - val_loss: 1.2902 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 5ms/step - accuracy: 0.5224 - loss: 1.3044 - val_accuracy: 0.5290 - val_loss: 1.2839 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 5ms/step - accuracy: 0.5228 - loss: 1.3037 - val_accuracy: 0.5294 - val_loss: 1.2832 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 5ms/step - accuracy: 0.5252 - loss: 1.2987 - val_accuracy: 0.5304 - val_loss: 1.2803 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 5ms/step - accuracy: 0.5271 - loss: 1.2942 - val_accuracy: 0.5302 - val_loss: 1.2811 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 5ms/step - accuracy: 0.5276 - loss: 1.2908 - val_accuracy: 0.5305 - val_loss: 1.2792 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 5ms/step - accuracy: 0.5277 - loss: 1.2915 - val_accuracy: 0.5315 - val_loss: 1.2781 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 5ms/step - accuracy: 0.5287 - loss: 1.2886 - val_accuracy: 0.5331 - val_loss: 1.2755 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 5ms/step - accuracy: 0.5294 - loss: 1.2862 - val_accuracy: 0.5328 - val_loss: 1.2756 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 5ms/step - accuracy: 0.5310 - loss: 1.2834 - val_accuracy: 0.5332 - val_loss: 1.2739 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 5ms/step - accuracy: 0.5323 - loss: 1.2796 - val_accuracy: 0.5325 - val_loss: 1.2758 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 5ms/step - accuracy: 0.5315 - loss: 1.2807 - val_accuracy: 0.5336 - val_loss: 1.2728 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 5ms/step - accuracy: 0.5334 - loss: 1.2775 - val_accuracy: 0.5340 - val_loss: 1.2732 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 5ms/step - accuracy: 0.5337 - loss: 1.2767 - val_accuracy: 0.5350 - val_loss: 1.2712 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 5ms/step - accuracy: 0.5338 - loss: 1.2749 - val_accuracy: 0.5336 - val_loss: 1.2721 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 5ms/step - accuracy: 0.5336 - loss: 1.2736 - val_accuracy: 0.5349 - val_loss: 1.2710 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 5ms/step - accuracy: 0.5343 - loss: 1.2724 - val_accuracy: 0.5348 - val_loss: 1.2712 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m184s\u001b[0m 5ms/step - accuracy: 0.5357 - loss: 1.2699 - val_accuracy: 0.5352 - val_loss: 1.2692 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 5ms/step - accuracy: 0.5360 - loss: 1.2697 - val_accuracy: 0.5357 - val_loss: 1.2693 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 5ms/step - accuracy: 0.5364 - loss: 1.2674 - val_accuracy: 0.5358 - val_loss: 1.2690 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 5ms/step - accuracy: 0.5361 - loss: 1.2678 - val_accuracy: 0.5357 - val_loss: 1.2702 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 5ms/step - accuracy: 0.5369 - loss: 1.2663 - val_accuracy: 0.5350 - val_loss: 1.2681 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "# callbacks for better training control\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# train with smaller batch size and more epochs\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    batch_size=32,  # smaller batch size\n",
    "    epochs=30,      # more epochs with early stopping\n",
    "    validation_split=0.15,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5360742211341858\n",
      "\u001b[1m12875/12875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'trust', 'anticipation', ..., 'sadness', 'joy',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "train_accuracy = history.history['accuracy']\n",
    "train_accuracy_nn4 = train_accuracy[-1]  # gets the last epoch's accuracy\n",
    "print(train_accuracy_nn4)\n",
    "\n",
    "# predict!\n",
    "\n",
    "# get raw probabilities\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "\n",
    "# convert to class predictions (gets the class with highest probability)\n",
    "y_test_pred_nn4 = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "predictions_labels_nn4 = label_encoder.inverse_transform(y_test_pred_nn4)\n",
    "predictions_labels_nn4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.42494"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neural network model #5 via keras - More hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 12ms/step - accuracy: 0.4494 - loss: 1.5053 - val_accuracy: 0.5024 - val_loss: 1.3559 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 11ms/step - accuracy: 0.4927 - loss: 1.3858 - val_accuracy: 0.5133 - val_loss: 1.3251 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m454s\u001b[0m 12ms/step - accuracy: 0.5020 - loss: 1.3617 - val_accuracy: 0.5178 - val_loss: 1.3130 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 12ms/step - accuracy: 0.5078 - loss: 1.3469 - val_accuracy: 0.5225 - val_loss: 1.3044 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 12ms/step - accuracy: 0.5129 - loss: 1.3348 - val_accuracy: 0.5223 - val_loss: 1.3002 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 12ms/step - accuracy: 0.5147 - loss: 1.3271 - val_accuracy: 0.5254 - val_loss: 1.2924 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 12ms/step - accuracy: 0.5176 - loss: 1.3210 - val_accuracy: 0.5284 - val_loss: 1.2876 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 12ms/step - accuracy: 0.5199 - loss: 1.3155 - val_accuracy: 0.5298 - val_loss: 1.2842 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m628s\u001b[0m 16ms/step - accuracy: 0.5225 - loss: 1.3089 - val_accuracy: 0.5307 - val_loss: 1.2829 - learning_rate: 0.0010\n",
      "Epoch 10/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 17ms/step - accuracy: 0.5234 - loss: 1.3064 - val_accuracy: 0.5320 - val_loss: 1.2795 - learning_rate: 0.0010\n",
      "Epoch 11/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m661s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 1.3002 - val_accuracy: 0.5332 - val_loss: 1.2772 - learning_rate: 0.0010\n",
      "Epoch 12/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 17ms/step - accuracy: 0.5272 - loss: 1.2962 - val_accuracy: 0.5319 - val_loss: 1.2770 - learning_rate: 0.0010\n",
      "Epoch 13/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m667s\u001b[0m 17ms/step - accuracy: 0.5291 - loss: 1.2915 - val_accuracy: 0.5337 - val_loss: 1.2722 - learning_rate: 0.0010\n",
      "Epoch 14/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 17ms/step - accuracy: 0.5299 - loss: 1.2890 - val_accuracy: 0.5350 - val_loss: 1.2721 - learning_rate: 0.0010\n",
      "Epoch 15/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m621s\u001b[0m 16ms/step - accuracy: 0.5317 - loss: 1.2850 - val_accuracy: 0.5349 - val_loss: 1.2704 - learning_rate: 0.0010\n",
      "Epoch 16/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m481s\u001b[0m 12ms/step - accuracy: 0.5318 - loss: 1.2835 - val_accuracy: 0.5360 - val_loss: 1.2677 - learning_rate: 0.0010\n",
      "Epoch 17/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m467s\u001b[0m 12ms/step - accuracy: 0.5329 - loss: 1.2809 - val_accuracy: 0.5366 - val_loss: 1.2668 - learning_rate: 0.0010\n",
      "Epoch 18/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 12ms/step - accuracy: 0.5346 - loss: 1.2770 - val_accuracy: 0.5363 - val_loss: 1.2668 - learning_rate: 0.0010\n",
      "Epoch 19/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 12ms/step - accuracy: 0.5343 - loss: 1.2772 - val_accuracy: 0.5372 - val_loss: 1.2659 - learning_rate: 0.0010\n",
      "Epoch 20/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m466s\u001b[0m 12ms/step - accuracy: 0.5363 - loss: 1.2760 - val_accuracy: 0.5375 - val_loss: 1.2644 - learning_rate: 0.0010\n",
      "Epoch 21/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 12ms/step - accuracy: 0.5373 - loss: 1.2714 - val_accuracy: 0.5378 - val_loss: 1.2623 - learning_rate: 0.0010\n",
      "Epoch 22/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m468s\u001b[0m 12ms/step - accuracy: 0.5373 - loss: 1.2703 - val_accuracy: 0.5381 - val_loss: 1.2622 - learning_rate: 0.0010\n",
      "Epoch 23/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 12ms/step - accuracy: 0.5381 - loss: 1.2688 - val_accuracy: 0.5382 - val_loss: 1.2632 - learning_rate: 0.0010\n",
      "Epoch 24/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 12ms/step - accuracy: 0.5394 - loss: 1.2646 - val_accuracy: 0.5394 - val_loss: 1.2607 - learning_rate: 0.0010\n",
      "Epoch 25/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 12ms/step - accuracy: 0.5388 - loss: 1.2644 - val_accuracy: 0.5395 - val_loss: 1.2606 - learning_rate: 0.0010\n",
      "Epoch 26/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 12ms/step - accuracy: 0.5410 - loss: 1.2607 - val_accuracy: 0.5399 - val_loss: 1.2596 - learning_rate: 0.0010\n",
      "Epoch 27/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m470s\u001b[0m 12ms/step - accuracy: 0.5413 - loss: 1.2595 - val_accuracy: 0.5404 - val_loss: 1.2580 - learning_rate: 0.0010\n",
      "Epoch 28/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 12ms/step - accuracy: 0.5424 - loss: 1.2560 - val_accuracy: 0.5401 - val_loss: 1.2600 - learning_rate: 0.0010\n",
      "Epoch 29/30\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m476s\u001b[0m 12ms/step - accuracy: 0.5429 - loss: 1.2568 - val_accuracy: 0.5403 - val_loss: 1.2597 - learning_rate: 0.0010\n",
      "Epoch 30/30\n",
      "\u001b[1m38660/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5431 - loss: 1.2546\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\u001b[1m38664/38664\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 12ms/step - accuracy: 0.5431 - loss: 1.2546 - val_accuracy: 0.5384 - val_loss: 1.2611 - learning_rate: 0.0010\n",
      "Restoring model weights from the end of the best epoch: 27.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(1024, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "# callbacks for better training control\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# train with smaller batch size and more epochs\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    batch_size=32,  # smaller batch size\n",
    "    epochs=30,      # more epochs with early stopping\n",
    "    validation_split=0.15,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5414515137672424\n",
      "\u001b[1m12875/12875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'trust', 'anticipation', ..., 'sadness', 'joy',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training accuracy\n",
    "train_accuracy = history.history['accuracy']\n",
    "train_accuracy_nn5 = train_accuracy[-1]  # gets the last epoch's accuracy\n",
    "print(train_accuracy_nn5)\n",
    "\n",
    "# predict!\n",
    "\n",
    "# get raw probabilities\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "\n",
    "# convert to class predictions (gets the class with highest probability)\n",
    "y_test_pred_nn5 = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "predictions_labels_nn5 = label_encoder.inverse_transform(y_test_pred_nn5)\n",
    "predictions_labels_nn5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.43554"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out other machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 4.744526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 97920\n",
      "[LightGBM] [Info] Number of data points in the train set: 1455563, number of used features: 384\n",
      "[LightGBM] [Info] Start training from score -3.597599\n",
      "[LightGBM] [Info] Start training from score -1.765956\n",
      "[LightGBM] [Info] Start training from score -2.347948\n",
      "[LightGBM] [Info] Start training from score -3.124281\n",
      "[LightGBM] [Info] Start training from score -1.037008\n",
      "[LightGBM] [Info] Start training from score -2.018196\n",
      "[LightGBM] [Info] Start training from score -3.396874\n",
      "[LightGBM] [Info] Start training from score -1.957809\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.8,\n",
       "               learning_rate=0.01, max_depth=6, n_estimators=500, n_jobs=-1,\n",
       "               random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.8,\n",
       "               learning_rate=0.01, max_depth=6, n_estimators=500, n_jobs=-1,\n",
       "               random_state=42, verbose=1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, feature_fraction=0.8,\n",
       "               learning_rate=0.01, max_depth=6, n_estimators=500, n_jobs=-1,\n",
       "               random_state=42, verbose=1)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    num_leaves=31,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    min_child_samples=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "## training!\n",
    "lgb_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'joy', ..., 'sadness', 'joy',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "y_train_pred_lgb = lgb_model.predict(X_train_scaled)\n",
    "y_test_pred_lgb = lgb_model.predict(X_test_scaled)\n",
    "\n",
    "train_accuracy_lgb = accuracy_score(y_train, y_train_pred_lgb)\n",
    "\n",
    "predictions_labels_lgb = label_encoder.inverse_transform(y_test_pred_lgb)\n",
    "predictions_labels_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47070171473168804\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Accuracy Not Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:56:18] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.01, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=500, n_jobs=-1,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.01,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=3,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "## training!\n",
    "xgb_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anticipation', 'anticipation', 'joy', ..., 'joy', 'joy',\n",
       "       'sadness'], dtype=object)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "y_train_pred_xgb = xgb_model.predict(X_train_scaled)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "train_accuracy_xgb = accuracy_score(y_train, y_train_pred_xgb)\n",
    "\n",
    "predictions_labels_xgb = label_encoder.inverse_transform(y_test_pred_xgb)\n",
    "predictions_labels_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4630565629931511\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Accuracy Not Good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    'id': X_test['tweet_id'],\n",
    "    'emotion': predictions_labels_nn5\n",
    "    # predictions_labels_rf0 OR predictions_labels_rf1 OR predictions_labels_nn0 OR predictions_labels_nn1 OR predictions_labels_nn2 OR\n",
    "    # predictions_labels_nn3 OR predictions_labels_nn4 OR predictions_labels_nn5\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x2c7743</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2c1eed</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2826ea</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x356d9a</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x20fd95</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  emotion\n",
       "0  0x2c7743      joy\n",
       "1  0x2c1eed      joy\n",
       "2  0x2826ea  sadness\n",
       "3  0x356d9a    trust\n",
       "4  0x20fd95      joy"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reorder df_results to match the submission format order\n",
    "\n",
    "submission_order_df = pd.read_csv('sampleSubmission.csv')\n",
    "\n",
    "# Create a copy of test_df to avoid modifying original\n",
    "test_ordered = df_results.copy()\n",
    "\n",
    "# Ensure tweet_id is the index\n",
    "if 'id' in test_ordered.columns:\n",
    "    test_ordered.set_index('id', inplace=True)\n",
    "    \n",
    "# Create a new DataFrame with the correct order\n",
    "test_df_ordered = pd.DataFrame(index=submission_order_df['id'])\n",
    "    \n",
    "# Join with test predictions to maintain order\n",
    "test_df_ordered = test_df_ordered.join(test_ordered)\n",
    "    \n",
    "# Reset index and rename to match submission format\n",
    "test_df_ordered.reset_index(inplace=True)\n",
    "test_df_ordered.rename(columns={'index': 'id'}, inplace=True)\n",
    "\n",
    "test_df_ordered.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_ordered.to_csv(\"submission_nn5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other techniques I tried but did not produce good results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Use TruncatedSVD - according to documentation, \n",
    "# Contrary to PCA, this estimator does not center the data before computing the singular value decomposition. \n",
    "# This means it can work with sparse matrices efficiently.\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "X_train_reduced = svd.fit_transform(text_train_tfidf)\n",
    "X_test_reduced = svd.transform(text_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select 50 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Scale the data before feature selection\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_reduced)\n",
    "X_test_scaled = scaler.transform(X_test_reduced)\n",
    "    \n",
    "# Initialize and fit feature selector\n",
    "selector = SelectKBest(score_func=mutual_info_classif, k=50)\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Most Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'trust', 'disgust', ..., 'trust', 'trust', 'sadness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "## predict!\n",
    "y_train_pred_dt = DT_model.predict(X_train_selected)\n",
    "y_test_pred_dt = DT_model.predict(X_test_selected)\n",
    "\n",
    "train_accuracy_dt = accuracy_score(y_train, y_train_pred_dt)\n",
    "\n",
    "predictions_labels = label_encoder.inverse_transform(y_test_pred_dt)\n",
    "predictions_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8178835268552443\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.25653"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "## build RandomForest model\n",
    "RF_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "## training!\n",
    "RF_model = RF_model.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'trust', 'disgust', ..., 'joy', 'anticipation', 'sadness'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict!\n",
    "y_train_pred_rf = RF_model.predict(X_train_selected)\n",
    "y_test_pred_rf = RF_model.predict(X_test_selected)\n",
    "\n",
    "train_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\n",
    "\n",
    "predictions_labels2 = label_encoder.inverse_transform(y_test_pred_rf)\n",
    "predictions_labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8178807787776964\n"
     ]
    }
   ],
   "source": [
    "print(train_accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Accuracy in Kaggle: 0.29806"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
